{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Try chatgpt for your task before fine-tuning. If chatgpt is not enough, then fine-tune it. Do not forget that chat-gpt may be sufficient for most simple tasks.\n",
        "\n",
        "To fine-tune the GPT-3.5 model, you need to convert each observation in your data to the following message template (Jsonline Format):"
      ],
      "metadata": {
        "id": "P4VmEGHIJY35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"{'messages': [{'role': 'system', 'content': 'Given a text, provide the following fields in a JSON format, where applicable:\\\n",
        "#                                              'person (only name/surname)', 'time (week, month, summer etc.)', 'currency (USD, EURO etc.)',\\\n",
        "#                                               and 'place (country, city etc.)'.'},\n",
        "#                  {'role': 'user', 'content': 'The White House is located in Washington, D.C.'},\n",
        "#                  {'role': 'assistant', 'content': \"{'Person': 'null', 'Time': 'null', 'Currency': 'null', 'Place': 'Washington, D.C.'}\"}]}\"\"\"\n",
        "\n",
        "# system: the instructions you give to the model.\n",
        "# user: the feature/independent variable/text of each observation in your data (X)\n",
        "# assistant: the dependent variable/target/label of each observation in your data (y)."
      ],
      "metadata": {
        "id": "1pMzh-puJgHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCEPg5weDWJR",
        "outputId": "553b8a81-8b24-42ec-b733-2c566026bc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MdfZxyAmvig",
        "outputId": "aada6fbb-4f1a-4b77-fae1-c5ff7a26d48f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "I16ivpcrDto6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('openai_key')"
      ],
      "metadata": {
        "id": "VYGy7Msa_tY1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI() #api_key=os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "1PKcnVGQmgTp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're getting 20 observations ready for NER fine tuning."
      ],
      "metadata": {
        "id": "5eMrh3BrLfzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= [\"After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.\",\n",
        "         \"Despite the fact that I had saved up 100.000 USD, I still found it difficult to afford a house in the city.\",\n",
        "         \"When I was a child, my grandparents would take me on long walks through the countryside, and those memories are still some of my most cherished.\",\n",
        "         \"After years of working in the corporate world, I decided to start my own business, and I've never looked back.\",\n",
        "         \"The ancient ruins we visited in Rome were so awe-inspiring that I found myself speechless.\",\n",
        "         \"Despite the fact that I had been practicing for months, my piano recital was a disaster, and I was humiliated.\",\n",
        "         \"When she traveled to Thailand, Mary was amazed by the beauty and serenity of the Buddhist temples.\",\n",
        "         \"My grandmother's estate, which had been passed down through several generations of our family, was the site of many cherished family gatherings.\",\n",
        "         \"When I was a student, I spent a semester studying abroad in France, and it was one of the most enriching experiences of my life.\",\n",
        "         \"After my grandfather passed away, my family and I spent weeks going through his belongings and reminiscing about his life.\",\n",
        "         \"The White House is located in Washington, D.C.\",\n",
        "         \"I need to exchange dollars for euros before I travel to Europe.\",\n",
        "         \"The exchange rate between the pound and the euro is favorable.\",\n",
        "         \"As a child, I used to spend my summers at my grandparents' farm, and those days are some of my most cherished memories.\",\n",
        "         \"After years of working for a multinational corporation, I decided to quit my job and travel the World.\",\n",
        "         \"My great-grandfather fought in World War II, and his stories about the war have been passed down through the generations of our family.\",\n",
        "         \"When I was in college, I spent a semester studying abroad in China, and it was an eye-opening experience.\",\n",
        "         \"My best friend and I have been planning a trip to South America for years, and we're finally going to make it happen this summer.\",\n",
        "         \"My parents own a small motel in a charming seaside town, and they've been running it for over 20 years.\",\n",
        "         \"Johnson and I decided to take a road trip across the United States during the summer after we graduated from college.\"]"
      ],
      "metadata": {
        "id": "Y1e-9iYwl7sF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Çıktıyı istediğiniz gibi düzenleyebilirsiniz. Çıktının sözlük formatında olmasını istedik, bu yüzden onu bu şekilde formatladık.\n",
        "\n",
        "target= [{\"Person\": \"John Wick\", \"Time\": \"several months\", \"Currency\": \"null\", \"Place\": \"Spain\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"USD\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"years\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"Rome\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"months\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"Mary\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"Thailand\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"semester\", \"Currency\": \"null\", \"Place\": \"France\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"weeks\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"Washington, D.C.\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": [\"dollars\", \"euros\"], \"Place\": \"Europe\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": [\"pound\", \"euro\"], \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": [\"summers\", \"those days\"], \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"years\", \"Currency\": \"null\", \"Place\": \"World\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"null\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"semester\", \"Currency\": \"null\", \"Place\": \"China\"},\n",
        "         {\"Person\": \"null\", \"Time\": [\"years\", \"summer\"], \"Currency\": \"null\", \"Place\": \"South America\"},\n",
        "         {\"Person\": \"null\", \"Time\": \"over 20 years\", \"Currency\": \"null\", \"Place\": \"null\"},\n",
        "         {\"Person\": \"Johnson\", \"Time\": \"summer\", \"Currency\": \"null\", \"Place\": \"United States\"}]"
      ],
      "metadata": {
        "id": "gSIpljkUJEdr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict={\"text\":prompt, \"target\":target}\n",
        "df=pd.DataFrame(my_dict)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "CYbO8k2ArW1B",
        "outputId": "d68c42ad-6ab0-46ca-ffb5-532c4a42c32f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  \\\n",
              "0   After spending several months studying abroad ...   \n",
              "1   Despite the fact that I had saved up 100.000 U...   \n",
              "2   When I was a child, my grandparents would take...   \n",
              "3   After years of working in the corporate world,...   \n",
              "4   The ancient ruins we visited in Rome were so a...   \n",
              "5   Despite the fact that I had been practicing fo...   \n",
              "6   When she traveled to Thailand, Mary was amazed...   \n",
              "7   My grandmother's estate, which had been passed...   \n",
              "8   When I was a student, I spent a semester study...   \n",
              "9   After my grandfather passed away, my family an...   \n",
              "10     The White House is located in Washington, D.C.   \n",
              "11  I need to exchange dollars for euros before I ...   \n",
              "12  The exchange rate between the pound and the eu...   \n",
              "13  As a child, I used to spend my summers at my g...   \n",
              "14  After years of working for a multinational cor...   \n",
              "15  My great-grandfather fought in World War II, a...   \n",
              "16  When I was in college, I spent a semester stud...   \n",
              "17  My best friend and I have been planning a trip...   \n",
              "18  My parents own a small motel in a charming sea...   \n",
              "19  Johnson and I decided to take a road trip acro...   \n",
              "\n",
              "                                               target  \n",
              "0   {'Person': 'John Wick', 'Time': 'several month...  \n",
              "1   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "2   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "3   {'Person': 'null', 'Time': 'years', 'Currency'...  \n",
              "4   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "5   {'Person': 'null', 'Time': 'months', 'Currency...  \n",
              "6   {'Person': 'Mary', 'Time': 'null', 'Currency':...  \n",
              "7   {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "8   {'Person': 'null', 'Time': 'semester', 'Curren...  \n",
              "9   {'Person': 'null', 'Time': 'weeks', 'Currency'...  \n",
              "10  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "11  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "12  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "13  {'Person': 'null', 'Time': ['summers', 'those ...  \n",
              "14  {'Person': 'null', 'Time': 'years', 'Currency'...  \n",
              "15  {'Person': 'null', 'Time': 'null', 'Currency':...  \n",
              "16  {'Person': 'null', 'Time': 'semester', 'Curren...  \n",
              "17  {'Person': 'null', 'Time': ['years', 'summer']...  \n",
              "18  {'Person': 'null', 'Time': 'over 20 years', 'C...  \n",
              "19  {'Person': 'Johnson', 'Time': 'summer', 'Curre...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90fa5820-c0ef-4290-9062-ea4b4866299c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>After spending several months studying abroad ...</td>\n",
              "      <td>{'Person': 'John Wick', 'Time': 'several month...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Despite the fact that I had saved up 100.000 U...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When I was a child, my grandparents would take...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After years of working in the corporate world,...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'years', 'Currency'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The ancient ruins we visited in Rome were so a...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Despite the fact that I had been practicing fo...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'months', 'Currency...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>When she traveled to Thailand, Mary was amazed...</td>\n",
              "      <td>{'Person': 'Mary', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My grandmother's estate, which had been passed...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When I was a student, I spent a semester study...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'semester', 'Curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>After my grandfather passed away, my family an...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'weeks', 'Currency'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The White House is located in Washington, D.C.</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I need to exchange dollars for euros before I ...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The exchange rate between the pound and the eu...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>As a child, I used to spend my summers at my g...</td>\n",
              "      <td>{'Person': 'null', 'Time': ['summers', 'those ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>After years of working for a multinational cor...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'years', 'Currency'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>My great-grandfather fought in World War II, a...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'null', 'Currency':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>When I was in college, I spent a semester stud...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'semester', 'Curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>My best friend and I have been planning a trip...</td>\n",
              "      <td>{'Person': 'null', 'Time': ['years', 'summer']...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>My parents own a small motel in a charming sea...</td>\n",
              "      <td>{'Person': 'null', 'Time': 'over 20 years', 'C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Johnson and I decided to take a road trip acro...</td>\n",
              "      <td>{'Person': 'Johnson', 'Time': 'summer', 'Curre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90fa5820-c0ef-4290-9062-ea4b4866299c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90fa5820-c0ef-4290-9062-ea4b4866299c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90fa5820-c0ef-4290-9062-ea4b4866299c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22c7b466-29ff-43a6-a0c3-118acb5b99d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22c7b466-29ff-43a6-a0c3-118acb5b99d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22c7b466-29ff-43a6-a0c3-118acb5b99d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e7cf7747-2905-409c-a21a-713f024e04ef\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e7cf7747-2905-409c-a21a-713f024e04ef button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.\",\n          \"My best friend and I have been planning a trip to South America for years, and we're finally going to make it happen this summer.\",\n          \"My great-grandfather fought in World War II, and his stories about the war have been passed down through the generations of our family.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df[\"text\"]\n",
        "y=df[\"target\"]"
      ],
      "metadata": {
        "id": "DBe6r_19v9fO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system=\"\"\"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\n",
        "<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time \\\n",
        "like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, \\\n",
        "'Place':<settlement like country, city, district etc.> </labels>\"\"\"\n",
        "system\n",
        "# commonly used delimiters:\n",
        "# triple quotes: \"\"\"\n",
        "# triple backticks: '''\n",
        "# riple dashes: ___\n",
        "# angle brackets : <>\n",
        "# curly brackets: {}\n",
        "# XML tags: <tag> </tag> ---> <text>This is sentence</text>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rWBYqiR8CHbc",
        "outputId": "5c82bd2d-b301-4cb8-9176-6335ee871555"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\\n<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, 'Place':<settlement like country, city, district etc.> </labels>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#system=\"\"\"Extract {labels} from text and return them in dict type.\n",
        "#labels: 'Person (name, surname)', 'Time (this week, last month, summer, next month etc.)', 'Currency (USD, EURO, etc.)', 'Place (country, city, etc.)'.\"\"\" #"
      ],
      "metadata": {
        "id": "Mnuvrc2FCRy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def convert_df_to_dict(X, y):\n",
        "  \"\"\"Converts X and y to dictionary format.\n",
        "\n",
        "  Args:\n",
        "    X: text\n",
        "    y: label\n",
        "\n",
        "  Returns:\n",
        "    A dataframe(as X and y) in dictionary format.\n",
        "  \"\"\"\n",
        "  #df = pd.read_csv(csv_file)\n",
        "  json_lines = []\n",
        "  for i, j in zip(X, y):\n",
        "    json_lines.append({\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": '<text>' + str(i) + '<text>'\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": str(j) # Dictionary formatındaki assistant content'i string'e dönüştürüyoruz.\n",
        "            }                     # Tüm contentler string'lerden oluşmalıdır, aksi takdirde Format validation bölümünde hata alırsınız.\n",
        "        ]\n",
        "    })\n",
        "\n",
        "  return json_lines"
      ],
      "metadata": {
        "id": "aw_wCp3irWtz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=convert_df_to_dict(X, y)"
      ],
      "metadata": {
        "id": "cCsO_z3qJEqZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVwTSGxKP1u3",
        "outputId": "eeaee2f5-236f-43e8-ceeb-be46f87cab57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': \"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\\n<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, 'Place':<settlement like country, city, district etc.> </labels>\"},\n",
              "  {'role': 'user',\n",
              "   'content': '<text>After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.<text>'},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"{'Person': 'John Wick', 'Time': 'several months', 'Currency': 'null', 'Place': 'Spain'}\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.jsonl\", \"w\") as f:\n",
        "    for item in train:\n",
        "        f.write(json.dumps(item) + \"\\n\")"
      ],
      "metadata": {
        "id": "vZrT07WQymOA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation and analysis for chat model fine-tuning\n",
        "\n",
        "**Data loading**, **Format validation**, **Token Counting Utilities**, **Data Warnings and Token Counts**, ve **Cost Estimation** bölümleri için aşağıdaki kod blokları OpenAI tarafından hazırlanmıştır. Ve ince ayardan önce kullanılması tavsiye edilir.\n",
        "\n",
        "Bu kod blokları, bir chatgpt modeline ince ayar yapmak için kullanılan datayı önceden işlemek ve analiz etmek için bir araç görevi görür. Biçim hatalarını kontrol eder, temel istatistikler sağlar ve ince ayar maliyetini belirlemek için gerekli olan token sayılarını tahmin eder."
      ],
      "metadata": {
        "id": "ACoGWUdfy_oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code blocks for the Data loading, Format validation, Token Counting Utilities, Data Warnings and Token Counts, and Cost Estimation sections are provided by OpenAI. And it is recommended to use them before fine tuning.\n",
        "\n",
        "These code blocks serve as a tool to pre-process and analyze the data used to fine-tune a chatgpt model. It checks for format errors, provides basic statistics and estimates the number of tokens needed to determine the cost of fine-tuning.\n",
        "\n",
        "Translated with DeepL.com (free version)"
      ],
      "metadata": {
        "id": "0txEQ63pMh3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "xRbs4Px5zD_O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "\n",
        "We first load the chat dataset from an example JSONL file."
      ],
      "metadata": {
        "id": "KTc7l0-8zLwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/train.jsonl\" # data_path değişkeni jsonl dosyasının yolunu belirtir.\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f: # with open() dosyayı açar ve json.loads() işlevini\n",
        "                                                  # kullanarak her satırı bir dict nesnesi olarak yükler.\n",
        "\n",
        "    dataset = [json.loads(line) for line in f] # tüm dict nesnelerini dataset listesine atıyoruz.\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt3gSCRpzOc3",
        "outputId": "a8c4491e-8cd6-4c4d-9551-6ba60b47ff80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 20\n",
            "First example:\n",
            "{'role': 'system', 'content': \"Extract the labels delimited by XML tags from text delimited by XML tags and return them in dict type.\\n<labels>'Person': <person names and surnames>, 'Time': <word or words indicating time like this week, last month, summer, next month etc.>', 'Currency':<all currencies like USD, EURO, etc.>, 'Place':<settlement like country, city, district etc.> </labels>\"}\n",
            "{'role': 'user', 'content': '<text>After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.<text>'}\n",
            "{'role': 'assistant', 'content': \"{'Person': 'John Wick', 'Time': 'several months', 'Currency': 'null', 'Place': 'Spain'}\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format validation\n",
        "\n",
        "Veri kümesindeki her bir gözlemin ince ayar API'sinin beklediği formata uygun olduğunu doğrulamak için çeşitli hata kontrolleri gerçekleştirebiliriz. Hatalar, daha kolay hata ayıklama için niteliklerine göre kategorize edilir.\n",
        "\n",
        "1.**Data Type Check(Veri Tipi Kontrolü)**:Veri setindeki her girdinin(input) bir dict olup olmadığını kontrol eder. Error type: data_type.\n",
        "\n",
        "2.**Presence of Message List(Mesaj Listesinin Varlığı)**: Her girdi için mesaj listesinin olup olmadığını kontrol eder. Error type: missing_messages_list.\n",
        "\n",
        "3.**Message Keys Check(Mesaj Anahtarları Kontrolü)**: Mesajların içerisindeki \"role\" ve \"content\" anahtarlarının varlığını kontrol eder. Error type: message_missing_key.\n",
        "\n",
        "4.**Unrecognized Keys in Messages(Mesajlardaki Tanınmayan Anahtarlar)**: Bir mesajın \"role\", \"content\" ve role_name(system, user, assistant) dışında anahtarları olup olmadığını kontrol eder. Error type: message_unrecognized_key.\n",
        "\n",
        "5.**Role Validation(role doğrulaması)**: \"Role\"lerin \"system\", \"user\", veya \"assistant\" olduğunu teyit eder. Error type: unrecognized_role.\n",
        "\n",
        "6.**Content Validation(content doğrulaması)**: contentin string bir ifade olduğunu teyit eder. Error type: missing_content.\n",
        "\n",
        "7.**Assistant Message Presence(Asistan Mesajı Varlığı:)**: mesajın içinde assistant'a ait bir içerik olup olmadığını kontrol eder. Error type: example_missing_assistant_message.\n",
        "\n",
        "Aşağıdaki kod, bu kontrolleri gerçekleştirir ve bulunan her türlü hatanın sayısını yazdırır. Bu, hata ayıklama ve veri kümesinin bir sonraki adımlara hazır olup olmadığını kontrol etme açısından faydalıdır."
      ],
      "metadata": {
        "id": "Cs-LTmYAzbsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can perform various error checks to verify that each observation in the dataset conforms to the format expected by the fine-tuning API. Errors are categorized according to their nature for easier debugging.\n",
        "\n",
        "1.Data Type Check: Checks whether each input in the dataset is a dict. Error type: data_type.\n",
        "\n",
        "2.Presence of Message List: Checks if there is a message list for each input. Error type: missing_messages_list.\n",
        "\n",
        "3.Message Keys Check: Checks for the presence of \"role\" and \"content\" keys in the messages. Error type: message_missing_key.\n",
        "\n",
        "4.Unrecognized Keys in Messages: Checks if a message has keys other than \"role\", \"content\" and role_name(system, user, assistant). Error type: message_unrecognized_key.\n",
        "\n",
        "5.Role Validation: Confirms that the \"roles\" are \"system\", \"user\", or \"assistant\". Error type: unrecognized_role.\n",
        "\n",
        "6.Content Validation: verifies that the content is a string expression. Error type: missing_content.\n",
        "\n",
        "7.Assistant Message Presence: checks if the message contains content belonging to the assistant. Error type: example_missing_assistant_message.\n",
        "\n",
        "The code below performs these checks and prints the number of any errors found. This is useful for debugging and checking that the dataset is ready for the next steps."
      ],
      "metadata": {
        "id": "sO3G42-YSXBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# bu fonksiyon, verilerin ince ayar için hazır olup olmadığını kontrol eder. Eksik veya geçersiz veriler için hata döndürür.\n",
        "# datada problem yoksa \"Hata bulunamadı\" mesajını döndürür."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M3niQ78z_Se",
        "outputId": "32e3ae82-6755-449b-89c3-01c1492ac5b9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token Counting Utilities\n",
        "\n",
        "Lets define a few helpful utilities to be used in the rest of the notebook."
      ],
      "metadata": {
        "id": "L2jSHp0y0jBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.05)}, {np.quantile(values, 0.95)}\")"
      ],
      "metadata": {
        "id": "WJNuG6gr0l-P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Warnings and Token Counts\n",
        "\n",
        "Aşağıdaki analizlerle, verilerdeki potansiyel sorunları, eksik mesajları belirleyebilir ve mesaj ve token sayıları hakkında istatistiksel bilgiler sağlayabiliriz.\n",
        "\n",
        "1.**Missing System/User Messages**: \"system\" veya \"user\" mesajı eksik olan gözlemleri sayar. Bu mesajlar, assistant'ın davranışını tanımlamak ve konuşmayı başlatmak için kritik öneme sahiptir.\n",
        "\n",
        "2.**Number of Messages Per Example**: Her bir gözlemdeki mesaj (system, user, assistant) sayısının dağılımını özetler ve diyalog karmaşıklığı hakkında bilgi sağlar. Her mesajın 3 ayrı bölümü olup olmadığını kontrol eder: system, user, assistant. Öyleyse, her mesajdaki parça sayısının min, max, mean, median, %5 ve %95 dilimlerdeki değeri her zaman 3 olacaktır. Aksi takdirde, bu değerler 3'ten farklı olacaktır.\n",
        "\n",
        "3.**Total Tokens Per Example**: Her gözlemdeki toplam token sayısının dağılımını hesaplar ve özetler. İnce ayar maliyetlerini anlamak için önemlidir. Bu, system, user ve assistant parçaları da dahil olmak üzere her mesajdaki toplam token sayısı ve dağılımları (mean, median, minimum, maximum, etc.) hakkında bilgi sağlar.\n",
        "\n",
        "4.**Tokens in Assistant's Messages**: her gözlemdeki assistant mesajlarındaki toekn sayısını hesaplar ve bu dağılımı özetler (mean, median, minimum, maximum, etc.). Assistant hakkında bilgi sağlar.\n",
        "\n",
        "5.**Token Limit Warnings**:  Herhangi bir gözlem maksimum toekn sınırını (4096 token) aşarsa kontrol eder, çünkü bu tür gözlemler ince ayar sırasında kırpılacak ve bu da veri kaybına neden olacaktır."
      ],
      "metadata": {
        "id": "QRZOQX8E3mgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the following analyses, we can identify potential problems in the data, missing messages and provide statistical information about the number of messages and tokens.\n",
        "\n",
        "1.Missing System/User Messages: Counts observations with missing \"system\" or \"user\" messages. These messages are critical for identifying the assistant's behavior and initiating the conversation.\n",
        "\n",
        "2.Number of Messages Per Example: Summarizes the distribution of the number of messages (system, user, assistant) in each observation and provides information about the dialog complexity. It checks if each message has 3 separate parts: system, user, assistant. If so, the min, max, mean, median, 5% and 95% of the number of parts in each message will always be 3. Otherwise, these values will be different from 3.\n",
        "\n",
        "3.Total Tokens Per Example: Calculates and summarizes the distribution of the total number of tokens in each observation. It is important to understand the fine-tuning costs. This provides information about the total number of tokens and their distribution (mean, median, minimum, maximum, etc.) in each message, including the system, user and assistant parts.\n",
        "\n",
        "4.Tokens in Assistant's Messages: calculates the number of tokens in assistant's messages in each observation and summarizes this distribution (mean, median, minimum, maximum, etc.). Provides information about the assistant.\n",
        "\n",
        "5.Token Limit Warnings: Checks if any observation exceeds the maximum token limit (4096 tokens), because such observations will be clipped during fine-tuning, resulting in data loss.\n"
      ],
      "metadata": {
        "id": "grHy-P57TCZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k4FwTMZ0pK2",
        "outputId": "b59c516c-1029-4990-a6ff-1b553d2ce597"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 146, 164\n",
            "mean / median: 156.05, 156.5\n",
            "p5 / p95: 147.9, 164.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 24, 29\n",
            "mean / median: 25.6, 24.5\n",
            "p5 / p95: 24.0, 29.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mD1LCr2x0u3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Estimation\n",
        "\n",
        "Bu son bölümde, ince ayar için kullanılacak toplam token sayısını tahmin ediyoruz, bu da maliyeti yaklaşık olarak tahmin etmemizi sağlıyor. Token sayısı arttıkça ince ayar işlemlerinin süresinin de artacağını belirtmekte fayda var."
      ],
      "metadata": {
        "id": "YbOEAqJK3-fI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this last section, we estimate the total number of tokens that will be used for fine-tuning, which allows us to approximate the cost. It is worth noting that as the number of tokens increases, the duration of the fine-tuning process will also increase - such observations will be truncated during fine-tuning, resulting in data loss."
      ],
      "metadata": {
        "id": "fJs-qFghTrQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "\n",
        "current_price=8 # bir milyon token başına fiyat, lütfen güncel fiyat için openai web sayfasını kontrol edin.\n",
        "print(f\"Estimate total costs ~{(n_epochs * n_billing_tokens_in_dataset)/1000000 * current_price}\")\n",
        "\n",
        "# İnce ayar için modele en az 10 gözlem verilmelidir. Aksi takdirde model hata döndürecektir. Ancak ince ayar için modele minimum 100, maksimum 25000\n",
        "# gözlem verilmesi tavsiye edilir.\n",
        "\n",
        "# GPT 3.5-Turbo modeli, ince ayar için varsayılan olarak 3 epoch ile çalışır. Ancak bu kod, verilerinizdeki gözlem sayısına göre minimum 1'den maksimum 25'e\n",
        "# kadar kaç epoch eğitim yapmanız gerektiğini size önerir.\n",
        "\n",
        "# Tüm eğitim boyunca işlenecek token sayısını ve bu token sayısına göre ince ayar maliyetini döndürür.\n",
        "\n",
        "# NOT: Bu bölüm yalnızca eğitim verilerine uygulanacaktır.\n",
        "\n",
        "# At least 10 observations must be given to the model for fine tuning. Otherwise the model will return an error. However, for fine tuning, the model should be given a minimum of 100 and a maximum of 25000\n",
        "# observation is recommended.\n",
        "\n",
        "# GPT 3.5-Turbo model works with 3 epochs by default for fine tuning. However, this code can be adjusted from a minimum of 1 to a maximum of 25, depending on the number of observations in your data.\n",
        "# Suggests how many epochs of training you need to do.\n",
        "\n",
        "# Returns the number of tokens to process over the entire training and the cost of fine-tuning based on this number of tokens.\n",
        "\n",
        "# NOTE: This section will only apply to training data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IdZITlY4Abs",
        "outputId": "62cf1151-b442-41a9-b9d6-12e024da8176"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~3121 tokens that will be charged for during training\n",
            "By default, you'll train for 5 epochs on this dataset\n",
            "By default, you'll be charged for ~15605 tokens\n",
            "Estimate total costs ~0.12484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_response = client.files.create(\n",
        "                                        file=open(\"/content/train.jsonl\", \"rb\"),\n",
        "                                        purpose=\"fine-tune\") # Train datasını ince ayar için hazırlıyoruz.\n",
        "\n",
        "training_file_id = training_response.id # Hazır olan train datası için oluşturulan ID’yi çekiyoruz.\n",
        "\n",
        "print(\"Training file id:\", training_file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqyOWQZQ4H2u",
        "outputId": "229a066f-37f7-43b6-bba7-d52269f26b8d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training file id: file-tjSKRw9BaK2gyHZ6PVYztW8X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_name = \"NER 2\"\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id, # Train datasının ID'si ince ayar modeline veriliyor. Train datasının ID'si mutlaka sağlanmalıdır\n",
        "    model=\"gpt-3.5-turbo\", # şimdilik mevcut tek model GPT-3.5-turbo'dur. GPT-4'ün yakın gelecekte kullanıma sunulmasını bekliyoruz.\n",
        "    suffix=suffix_name, # İnce ayar yapılan modelin ismine kendi seçeceğimiz bir ek ekleyebiliyoruz ancak modelin ismini tam olarak belirleyemiyoruz.\n",
        "    hyperparameters={\"n_epochs\":5}, # Yalnızca Epoch, batch size parametresini ayarlamamıza izin veriliyor. Diğer parametreleri düzenlememize izin verilmiyor.\n",
        "                                    # Önerilen epoch sayısı 5 olduğundan epoch'u 5 olarak ayarladık.\n",
        ")\n",
        "\n",
        "job_id = response.id # The ID of fine-tune model.\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F702yNIP4bVH",
        "outputId": "22a11fca-fd76-4ec5-f91f-0493557df0b6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FineTuningJob(id='ftjob-TrN7uTLOFRnjdSpwBb6nk7CS', created_at=1720877966, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-2DK8uJ3r4XlwyMWXFl6PyYe2', result_files=[], seed=912087108, status='validating_files', trained_tokens=None, training_file='file-tjSKRw9BaK2gyHZ6PVYztW8X', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='NER 2')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_id"
      ],
      "metadata": {
        "id": "9ZZte7beSdkh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f338f0e1-5f2f-4050-fdc3-1290ead37997"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-TrN7uTLOFRnjdSpwBb6nk7CS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#client.fine_tuning.jobs.retrieve(job_id) # İnce ayar hakkında genel bilgiler alıyoruz."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NsEywLJ4ref",
        "outputId": "91b5ce43-4c71-4391-f1a3-9b47f3543925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-hJIUvUV1dtOd4gLx91uOVr1G', created_at=1720542181, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=616637618, status='validating_files', trained_tokens=None, training_file='file-1r3RenLntZrdVJpIQEVki9tq', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='NER 2')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqSllWWzTuPI",
        "outputId": "2555113d-1ef0-434e-e993-d4419781fc2d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-TrN7uTLOFRnjdSpwBb6nk7CS', created_at=1720877966, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL35ZL', finished_at=1720878268, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-2DK8uJ3r4XlwyMWXFl6PyYe2', result_files=['file-YpGoatKQvGolf2yXVat9s2wK'], seed=912087108, status='succeeded', trained_tokens=15405, training_file='file-tjSKRw9BaK2gyHZ6PVYztW8X', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='NER 2')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10) # Son 10 adımdaki ince ayar işleminin olaylarını görüntüler."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSL-R7PZ4u39",
        "outputId": "a4c5c843-09bb-4a66-c516-f6dc1178bd1d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-UbQMk2kX0CqqmtOKJ0S8Gk7T', created_at=1720878272, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-PMAHSwQHmaKO1lalVBuMbA8I', created_at=1720878269, level='info', message='New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL35ZL', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-MLqpknP73bzfwLUTKmI8ZmUR', created_at=1720878269, level='info', message='Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL37h1:ckpt-step-80', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-A9zHF2ajYK4cyL3RWTOFqStP', created_at=1720878269, level='info', message='Checkpoint created at step 60 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL2kOH:ckpt-step-60', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-5kuPQYwL0uNbjzAftrfr0LcR', created_at=1720878268, level='info', message='Step 100/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 100, 'train_loss': 2.630825690630445e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-vB9ZiASepOeI2Kfu5ErOCZKQ', created_at=1720878265, level='info', message='Step 99/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 99, 'train_loss': 2.934382621333498e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-CsYBMUW7F61xaCFp9p0Tqebj', created_at=1720878263, level='info', message='Step 98/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 98, 'train_loss': 2.934382621333498e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-b3XQTv4Nbg5GbTjCKc07vTv1', created_at=1720878263, level='info', message='Step 97/100: training loss=0.43', object='fine_tuning.job.event', data={'step': 97, 'train_loss': 0.42887750267982483, 'total_steps': 100, 'train_mean_token_accuracy': 0.9666666388511658}, type='metrics'), FineTuningJobEvent(id='ftevent-RyqoPa1TCzrHrKCNR72DFyrJ', created_at=1720878261, level='info', message='Step 96/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 96, 'train_loss': 2.934382621333498e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-r6uYX6oR1VEbVj4rLGCbweMx', created_at=1720878259, level='info', message='Step 95/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 95, 'train_loss': 3.178914482759865e-07, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')], object='list', has_more=True)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response= client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
        "\n",
        "events=response.data\n",
        "\n",
        "events.reverse() # İnce ayar işleminin ilk adımları başlangıçta olacak şekilde, rever() fonksiyonunu kullanarak\n",
        "                 # ince ayar adımlarının sırasını tersine çeviriyoruz.\n",
        "\n",
        "for event in events:\n",
        "  print(event.message)\n",
        "\n",
        "# Her adım için training loss skorlarını alıyoruz."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrHbhby25Rve",
        "outputId": "e041078c-5210-4aaf-9aa3-d67d9dc051a7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 85/100: training loss=0.00\n",
            "Step 86/100: training loss=0.00\n",
            "Step 87/100: training loss=0.00\n",
            "Step 88/100: training loss=0.00\n",
            "Step 89/100: training loss=0.00\n",
            "Step 90/100: training loss=0.00\n",
            "Step 91/100: training loss=0.46\n",
            "Step 92/100: training loss=0.00\n",
            "Step 93/100: training loss=0.00\n",
            "Step 94/100: training loss=0.00\n",
            "Step 95/100: training loss=0.00\n",
            "Step 96/100: training loss=0.00\n",
            "Step 97/100: training loss=0.43\n",
            "Step 98/100: training loss=0.00\n",
            "Step 99/100: training loss=0.00\n",
            "Step 100/100: training loss=0.00\n",
            "Checkpoint created at step 60 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL2kOH:ckpt-step-60\n",
            "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL37h1:ckpt-step-80\n",
            "New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL35ZL\n",
            "The job has successfully completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#client.fine_tuning.jobs.cancel(job_id)\n",
        "\n",
        "# You can cancel the fine-tuning process you have started with this code. However, the fine-tuning process will start in 5-10 minutes,\n",
        "# so you need to cancel it before that. If you don't, you won't be able to cancel it."
      ],
      "metadata": {
        "id": "bAfZutEWVkwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f238c8-1f1a-4f7f-83bb-c7e3fe2c6e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-nKraJjw1ggsXvBT8TNkrSoZw', created_at=1713810376, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=483893693, status='cancelled', trained_tokens=None, training_file='file-QETofvgMzM3vaF3XZ7HywbLP', validation_file=None, integrations=[], user_provided_suffix='NER')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "_jgiLQPuV1JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # İnce ayar hakkında genel bilgiler alıyoruz öncelikle. burdan fine-tune model ismini çekeceğiz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq8jJwcKV6qd",
        "outputId": "4a3d2f52-cee4-4a44-e1be-723ecc414bfc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-TrN7uTLOFRnjdSpwBb6nk7CS', created_at=1720877966, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL35ZL', finished_at=1720878268, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-2DK8uJ3r4XlwyMWXFl6PyYe2', result_files=['file-YpGoatKQvGolf2yXVat9s2wK'], seed=912087108, status='succeeded', trained_tokens=15405, training_file='file-tjSKRw9BaK2gyHZ6PVYztW8X', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='NER 2')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name= client.fine_tuning.jobs.retrieve(job_id).fine_tuned_model # model ismini çekiyoruz.\n",
        "model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KuSeT27fp6fu",
        "outputId": "291fafc1-e8ab-489d-84d3-f23f8e027b05"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ft:gpt-3.5-turbo-0125:personal:ner-2:9kXL35ZL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": \"My grandmother was a talented seamstress, and she taught me how to sew when I was young, which sparked a lifelong passion for fashion and design.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P4VHMw78kN1",
        "outputId": "a666e206-637a-4032-b6e2-e5604aed8518"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Person': 'null', 'Time': 'null', 'Currency': 'null', 'Place': 'null'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": \"While I was on summer vacation, Joseph earned 100 dollars and 100 euros in Turkey and returned to Germany and England.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEH9Asxy-BW3",
        "outputId": "1225f084-bd9e-468b-ebd0-d1449fddcccd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Person': 'Joseph', 'Time': 'summer', 'Currency': ['dollars', 'euros'], 'Place': ['Turkey', 'Germany', 'England']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": \"Johnson Walker and Maria got married last month. They bought a house in London for 100,000 sterling pounds.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXCUPZMk-Wo9",
        "outputId": "382da3bb-39ed-45be-c025-db2900525115"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Person': 'Johnson Walker and Maria', 'Time': 'last month', 'Currency': 'sterling pounds', 'Place': 'London'}\n"
          ]
        }
      ]
    }
  ]
}