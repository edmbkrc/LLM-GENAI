{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Try chatgpt for your task before fine-tuning. If chatgpt is not enough, then fine-tune it. Do not forget that chat-gpt may be sufficient for most simple tasks.\n",
        "\n",
        "To fine-tune the GPT-3.5 model, you need to convert each observation in your data to the following message template (Jsonline Format):"
      ],
      "metadata": {
        "id": "wBRzu-Yk4Btb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"{'messages': [{'role': 'system', 'content': 'Detect sentiment in the text.'},\n",
        "#                {'role': 'user', 'content': 'It is a very nice pair of pants. I recommend it to everyone.'},\n",
        "#                {'role': 'assistant', 'content': 'possitive'}]}\"\n",
        "\n",
        "# system: the instructions you give to the model.\n",
        "# user: the feature/independent variable/text of each observation in your data (X)\n",
        "# assistant: the dependent variable/target/label of each observation in your data (y)."
      ],
      "metadata": {
        "id": "P_X9Ptrr5HoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b7oLIrkJnHm",
        "outputId": "2c09fab8-6fc5-4bb5-aaea-fbc36e7efacd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5ZLFxvoohMT",
        "outputId": "64985d87-5b55-40ff-f7fc-61748242abb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOqXTmLNk47Q",
        "outputId": "a4600115-0069-4586-9086-83f9e6d26dc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yR7fCAUpkrJY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/GENAI-LLM/Fıne Tuning and Function Calling/clothing_reviews.csv\")\n",
        "df.head()\n",
        "\n",
        "# We will fine-tune a data set with 300 observations."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0D2xCVuUk2Ax",
        "outputId": "768ab583-b1fc-4650-a3d0-2d070835eaab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  I love this shirt! great fabric, nice quality,...  positive\n",
              "1  I recently purchased this tunic and love it! i...  positive\n",
              "2  I love this top, it's design is very pretty an...  positive\n",
              "3  Love this sweater! it's really flattering, lon...  positive\n",
              "4  I wanted to like this so much. it's a great go...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de86ceff-f10c-4c0c-9552-4090c8779a96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this shirt! great fabric, nice quality,...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I recently purchased this tunic and love it! i...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I love this top, it's design is very pretty an...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Love this sweater! it's really flattering, lon...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I wanted to like this so much. it's a great go...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de86ceff-f10c-4c0c-9552-4090c8779a96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de86ceff-f10c-4c0c-9552-4090c8779a96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de86ceff-f10c-4c0c-9552-4090c8779a96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6aa74598-ca45-42b5-8eb2-d77cf6a6088f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6aa74598-ca45-42b5-8eb2-d77cf6a6088f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6aa74598-ca45-42b5-8eb2-d77cf6a6088f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# We will fine-tune a data set with 300 observations\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I recently purchased this tunic and love it! its not to big, hangs just right, arm holes are not to big and the material is very comfortable! looks great with white jeans, shorts, or just jeans. i will get a lot of wear all year round! fits true to size. oh, slimming too!\",\n          \"I wanted to like this so much. it's a great good girl dress, church dress. however, it makes no sense. it's a summer dress with massively thick lining that snags i'm petite and busty and it made me look and feel very wide.\",\n          \"I love this top, it's design is very pretty and like nothing that i have. i think this top runs true to size, i'm usually an xs/s in tops and i went with the s for this one and it fits great. i will say that the top layer of material will snag very easily, so while wearing it you have to be very careful!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffdfINE6EcHV",
        "outputId": "7131d9a1-3d5c-4ede-9b31-0b3e5f5d7bb3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.fig = plt.figure(figsize = (7,5))\n",
        "ax = sns.countplot(x=\"label\",\n",
        "                   data=df)\n",
        "ax.bar_label(ax.containers[0]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "KxG1fd_UlXE3",
        "outputId": "ef726486-045e-4a66-e4ef-2aca3f95eec9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVUoaIGhlkGY",
        "outputId": "8ad314d8-b6f7-4aee-971c-fae56fdec9db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=101)"
      ],
      "metadata": {
        "id": "_6dYx0KAu5Z4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spR4NNO81iWr",
        "outputId": "0f781c3f-36f0-4041-fda4-0890d54a8c35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225\n",
            "75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiJz3_qFoXLt",
        "outputId": "b2b11eaa-a917-4021-c3c5-ee2375d2c7c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283    The skirt is comfortable and as pictured. it a...\n",
              "184    Saw this online and ran over to the store to t...\n",
              "237    For me, this top ran true to size. i'm so glad...\n",
              "230    All the colors are beautiful, the white is a t...\n",
              "224    What a fun dress to wear. it feels great, and ...\n",
              "                             ...                        \n",
              "287    I am pleased with this skirt. the jean materia...\n",
              "43     Love this top! i receive so many compliments w...\n",
              "88     Received this dress yesterday, love it!\\r\\nmy ...\n",
              "32     These jeans are very comfortable. the distress...\n",
              "284    I usually wear a size xs or s in retailer tops...\n",
              "Name: text, Length: 225, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def convert_df_to_dict(X, y):\n",
        "  \"\"\"Converts X and y to dictionary format.\n",
        "\n",
        "  Args:\n",
        "    X: text\n",
        "    y: label\n",
        "\n",
        "  Returns:\n",
        "    A dataframe(as X and y) in dictionary format.\n",
        "  \"\"\"\n",
        "\n",
        "  dictionary = []\n",
        "  for i, j in zip(X, y):\n",
        "    dictionary.append({\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Detect sentiment in the text.\" # system content'i tüm gözlemler için aynı olacaktır.\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": str(i)\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": str(j)\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "\n",
        "  return dictionary\n",
        "\n",
        "# Gözlemleri JSONLine formatına dönüştürmek için öncelikle onları dict formatına dönüştürmemiz gerekiyor."
      ],
      "metadata": {
        "id": "RY6NHIN0lzEf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = convert_df_to_dict(X_train, y_train)\n",
        "test = convert_df_to_dict(X_test, y_test)\n",
        "\n",
        "# Train ve test verilerini ayrı ayrı dictionary formatına dönüştürüyoruz."
      ],
      "metadata": {
        "id": "A3kUGrxlraUQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV6TOTzsA9rM",
        "outputId": "9597861a-d7dd-4c37-d48e-d63c77dbc5d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'messages': [{'role': 'system', 'content': 'Detect sentiment in the text.'},\n",
              "   {'role': 'user',\n",
              "    'content': 'The skirt is comfortable and as pictured. it also ran tts. i\\'m 5\\'5\" tall and weigh 140 lbs. i had the medium and didn\\'t need to size up to a large. when you put the skirt on a normal body, it looks like you are wearing an easter egg... and not in a good way.'},\n",
              "   {'role': 'assistant', 'content': 'negative'}]},\n",
              " {'messages': [{'role': 'system', 'content': 'Detect sentiment in the text.'},\n",
              "   {'role': 'user',\n",
              "    'content': \"Saw this online and ran over to the store to try it on. so lovely! i thought i would want it in the cream color but the blue was so lovely in person. it's like a muted blue that makes it so versatile. the detail in the back is gorgeous and so flattering. the safety pin is such a unique touch. it's nice and warm, just not super soft, but not scratchy. i do think i will be extra careful with it because it seems like it could get caught on things easily.\"},\n",
              "   {'role': 'assistant', 'content': 'positive'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train[0]) # the type of observations is dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEHj56gOTTE",
        "outputId": "63accf67-646c-464d-8221-e7fe3a263e3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.jsonl\", \"w\") as f:\n",
        "    for item in train:\n",
        "        f.write(json.dumps(item) + \"\\n\") # Python'da bir dictionary'i JSON formatına dönüştürmek için json.dumps() fonksiyonu kullanılır.\n",
        "                                         # Bu fonksiyon dictionary'i bir JSON string'e dönüştürür.\n",
        "\n",
        "# İnce ayar için modele besleyeceğimiz train ve test datası JSON line formatında olmalıdır. Bunun için dictionary formatındaki tüm gözlemleri\n",
        "# JSON line formatına dönüştürüyoruz.\n",
        "\n",
        "# JSON formatı dictionary formatının string'e dönüştürülmesidir.\n",
        "\n",
        "# dict format: {'name': 'johnson', 'age':44}\n",
        "# json format: \"{'name': 'johnson', 'age':'44'}\"\n",
        "\n",
        "\n",
        "# Python uses the json.dumps() function to convert a dictionary to JSON format.\n",
        " # This function converts the dictionary into a JSON string.\n",
        "\n",
        "# For fine tuning, the train and test data that we will feed to the model should be in JSON line format. For this, all observations in dictionary format\n",
        "# We convert to JSON line format.\n",
        "\n",
        "# JSON format is the conversion of dictionary format to string.\n",
        "\n",
        "# dict format: {'name': 'johnson', 'age':44}\n",
        "# json format: \"{'name': 'johnson', 'age':'44'}\""
      ],
      "metadata": {
        "id": "i7M9n1ozKjDN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"test.jsonl\", \"w\") as f:\n",
        "    for item in test:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "# Train datasına yaptığımız JSON line dönüşümünün aynısını test datasına da uyguluyoruz."
      ],
      "metadata": {
        "id": "8NRNwOh9KvhR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import codecs\n",
        "\n",
        "with codecs.open('train.jsonl', 'r', encoding='utf-8') as f:\n",
        "  a = 0\n",
        "  for line in f:\n",
        "    print(type(line))\n",
        "    print(line)\n",
        "    a+=1\n",
        "\n",
        "    if a==2:\n",
        "      break\n",
        "\n",
        "# JSON line formatına dönüştürülen tüm gözlemlerin string type'da olduğunu görebiliriz."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCL6YmEcR2Bi",
        "outputId": "dee4c63a-6769-4148-f869-21bba1bdb0f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "{\"messages\": [{\"role\": \"system\", \"content\": \"Detect sentiment in the text.\"}, {\"role\": \"user\", \"content\": \"The skirt is comfortable and as pictured. it also ran tts. i'm 5'5\\\" tall and weigh 140 lbs. i had the medium and didn't need to size up to a large. when you put the skirt on a normal body, it looks like you are wearing an easter egg... and not in a good way.\"}, {\"role\": \"assistant\", \"content\": \"negative\"}]}\n",
            "\n",
            "<class 'str'>\n",
            "{\"messages\": [{\"role\": \"system\", \"content\": \"Detect sentiment in the text.\"}, {\"role\": \"user\", \"content\": \"Saw this online and ran over to the store to try it on. so lovely! i thought i would want it in the cream color but the blue was so lovely in person. it's like a muted blue that makes it so versatile. the detail in the back is gorgeous and so flattering. the safety pin is such a unique touch. it's nice and warm, just not super soft, but not scratchy. i do think i will be extra careful with it because it seems like it could get caught on things easily.\"}, {\"role\": \"assistant\", \"content\": \"positive\"}]}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation and analysis for chat model fine-tuning\n",
        "\n",
        "\n",
        "**Data loading**, **Format validation**, **Token Counting Utilities**, **Data Warnings and Token Counts**, ve **Cost Estimation** bölümleri için aşağıdaki kod blokları OpenAI tarafından hazırlanmıştır. Ve ince ayardan önce kullanılması tavsiye edilir.\n",
        "\n",
        "Bu kod blokları, bir chatgpt modeline ince ayar yapmak için kullanılan datayı önceden işlemek ve analiz etmek için bir araç görevi görür. Biçim hatalarını kontrol eder, temel istatistikler sağlar ve ince ayar maliyetini belirlemek için gerekli olan token sayılarını tahmin eder."
      ],
      "metadata": {
        "id": "qH3I4tzySovp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code blocks for the Data loading, Format validation, Token Counting Utilities, Data Warnings and Token Counts, and Cost Estimation sections are provided by OpenAI. And it is recommended to use them before fine tuning.\n",
        "\n",
        "These code blocks serve as a tool to pre-process and analyze the data used to fine-tune a chatgpt model. It checks for format errors, provides basic statistics and estimates the number of tokens needed to determine the cost of fine-tuning."
      ],
      "metadata": {
        "id": "-KkAd363CZuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "2UAjU36rTJpL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "\n",
        "We first load the chat dataset from an example JSONL file."
      ],
      "metadata": {
        "id": "2Ws8lfn7TPzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/train.jsonl\" # data_path değişkeni jsonl dosyasının yolunu belirtir.\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f: # with open() dosyayı açar ve json.loads() işlevini\n",
        "                                                  # kullanarak her satırı bir dict nesnesi olarak yükler.\n",
        "\n",
        "    dataset = [json.loads(line) for line in f] # tüm dict nesnelerini dataset listesine atıyoruz.\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(type(message))\n",
        "    print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DA0XyMBTLe5",
        "outputId": "fdc1c17b-8e9f-43c0-8944-185f64685fcf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 225\n",
            "First example:\n",
            "<class 'dict'>\n",
            "{'role': 'system', 'content': 'Detect sentiment in the text.'}\n",
            "<class 'dict'>\n",
            "{'role': 'user', 'content': 'The skirt is comfortable and as pictured. it also ran tts. i\\'m 5\\'5\" tall and weigh 140 lbs. i had the medium and didn\\'t need to size up to a large. when you put the skirt on a normal body, it looks like you are wearing an easter egg... and not in a good way.'}\n",
            "<class 'dict'>\n",
            "{'role': 'assistant', 'content': 'negative'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format validation\n",
        "\n",
        "Veri kümesindeki her bir gözlemin ince ayar API'sinin beklediği formata uygun olduğunu doğrulamak için çeşitli hata kontrolleri gerçekleştirebiliriz. Hatalar, daha kolay hata ayıklama için niteliklerine göre kategorize edilir.\n",
        "\n",
        "1.**Data Type Check(Veri Tipi Kontrolü)**:Veri setindeki her girdinin(input) bir dict olup olmadığını kontrol eder. Error type: data_type.\n",
        "\n",
        "2.**Presence of Message List(Mesaj Listesinin Varlığı)**: Her girdi için mesaj listesinin olup olmadığını kontrol eder. Error type: missing_messages_list.\n",
        "\n",
        "3.**Message Keys Check(Mesaj Anahtarları Kontrolü)**: Mesajların içerisindeki \"role\" ve \"content\" anahtarlarının varlığını kontrol eder. Error type: message_missing_key.\n",
        "\n",
        "4.**Unrecognized Keys in Messages(Mesajlardaki Tanınmayan Anahtarlar)**: Bir mesajın \"role\", \"content\" ve role_name(system, user, assistant) dışında anahtarları olup olmadığını kontrol eder. Error type: message_unrecognized_key.\n",
        "\n",
        "5.**Role Validation(role doğrulaması)**: \"Role\"lerin \"system\", \"user\", veya \"assistant\" olduğunu teyit eder. Error type: unrecognized_role.\n",
        "\n",
        "6.**Content Validation(content doğrulaması)**: contentin string bir ifade olduğunu teyit eder. Error type: missing_content.\n",
        "\n",
        "7.**Assistant Message Presence(Asistan Mesajı Varlığı:)**: mesajın içinde assistant'a ait bir içerik olup olmadığını kontrol eder. Error type: example_missing_assistant_message.\n",
        "\n",
        "Aşağıdaki kod, bu kontrolleri gerçekleştirir ve bulunan her türlü hatanın sayısını yazdırır. Bu, hata ayıklama ve veri kümesinin bir sonraki adımlara hazır olup olmadığını kontrol etme açısından faydalıdır."
      ],
      "metadata": {
        "id": "5Qfu9GeYTjxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can perform various error checks to verify that each observation in the dataset conforms to the format expected by the fine-tuning API. Errors are categorized according to their nature for easier debugging.\n",
        "\n",
        "1.Data Type Check: Checks whether each input in the dataset is a dict. Error type: data_type.\n",
        "\n",
        "2.Presence of Message List: Checks if there is a message list for each input. Error type: missing_messages_list.\n",
        "\n",
        "3.Message Keys Check: Checks for the presence of \"role\" and \"content\" keys in the messages. Error type: message_missing_key.\n",
        "\n",
        "4.Unrecognized Keys in Messages: Checks if a message has keys other than \"role\", \"content\" and role_name(system, user, assistant). Error type: message_unrecognized_key.\n",
        "\n",
        "5.Role Validation: Confirms that the \"roles\" are \"system\", \"user\", or \"assistant\". Error type: unrecognized_role.\n",
        "\n",
        "6.Content Validation: verifies that the content is a string expression. Error type: missing_content.\n",
        "\n",
        "7.Assistant Message Presence: checks if the message contains content belonging to the assistant. Error type: example_missing_assistant_message.\n",
        "\n",
        "\n",
        "The code below performs these checks and prints the number of any errors found. This is useful for debugging and checking that the dataset is ready for the next steps."
      ],
      "metadata": {
        "id": "09y8cwJLC88z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# bu fonksiyon, verilerin ince ayar için hazır olup olmadığını kontrol eder. Eksik veya geçersiz veriler için hata döndürür.\n",
        "# datada problem yoksa \"Hata bulunamadı\" mesajını döndürür."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaCwPIfrTLmR",
        "outputId": "2c4185e6-1451-4ace-a9bd-6b75a424db6e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token Counting Utilities\n",
        "\n",
        "Lets define a few helpful utilities to be used in the rest of the notebook."
      ],
      "metadata": {
        "id": "esD69V_LTrwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.05)}, {np.quantile(values, 0.95)}\")"
      ],
      "metadata": {
        "id": "_wxxwwAgTLtI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Warnings and Token Counts\n",
        "\n",
        "Aşağıdaki analizlerle, verilerdeki potansiyel sorunları, eksik mesajları belirleyebilir ve mesaj ve token sayıları hakkında istatistiksel bilgiler sağlayabiliriz.\n",
        "\n",
        "1.**Missing System/User Messages**: \"system\" veya \"user\" mesajı eksik olan gözlemleri sayar. Bu mesajlar, assistant'ın davranışını tanımlamak ve konuşmayı başlatmak için kritik öneme sahiptir.\n",
        "\n",
        "2.**Number of Messages Per Example**: Her bir gözlemdeki mesaj (system, user, assistant) sayısının dağılımını özetler ve diyalog karmaşıklığı hakkında bilgi sağlar. Her mesajın 3 ayrı bölümü olup olmadığını kontrol eder: system, user, assistant. Öyleyse, her mesajdaki parça sayısının min, max, mean, median, %5 ve %95 dilimlerdeki değeri her zaman 3 olacaktır. Aksi takdirde, bu değerler 3'ten farklı olacaktır.\n",
        "\n",
        "3.**Total Tokens Per Example**: Her gözlemdeki toplam token sayısının dağılımını hesaplar ve özetler. İnce ayar maliyetlerini anlamak için önemlidir. Bu, system, user ve assistant parçaları da dahil olmak üzere her mesajdaki toplam token sayısı ve dağılımları (mean, median, minimum, maximum, etc.) hakkında bilgi sağlar.\n",
        "\n",
        "4.**Tokens in Assistant's Messages**: her gözlemdeki assistant mesajlarındaki toekn sayısını hesaplar ve bu dağılımı özetler (mean, median, minimum, maximum, etc.). Assistant hakkında bilgi sağlar.\n",
        "\n",
        "5.**Token Limit Warnings**:  Herhangi bir gözlem maksimum toekn sınırını (4096 token) aşarsa kontrol eder, çünkü bu tür gözlemler ince ayar sırasında kırpılacak ve bu da veri kaybına neden olacaktır."
      ],
      "metadata": {
        "id": "NTgrQJlcT6CP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the following analyses, we can identify potential problems in the data, missing messages and provide statistical information about the number of messages and tokens.\n",
        "\n",
        "1.Missing System/User Messages: Counts observations with missing \"system\" or \"user\" messages. These messages are critical for identifying the assistant's behavior and initiating the conversation.\n",
        "\n",
        "2.Number of Messages Per Example: Summarizes the distribution of the number of messages (system, user, assistant) in each observation and provides information about the dialog complexity. It checks if each message has 3 separate parts: system, user, assistant. If so, the min, max, mean, median, 5% and 95% of the number of parts in each message will always be 3. Otherwise, these values will be different from 3.\n",
        "\n",
        "3.Total Tokens Per Example: Calculates and summarizes the distribution of the total number of tokens in each observation. It is important to understand the fine-tuning costs. This provides information about the total number of tokens and their distribution (mean, median, minimum, maximum, etc.) in each message, including the system, user and assistant parts.\n",
        "\n",
        "4.Tokens in Assistant's Messages: calculates the number of tokens in assistant's messages in each observation and summarizes this distribution (mean, median, minimum, maximum, etc.). Provides information about the assistant.\n",
        "\n",
        "5.Token Limit Warnings: Checks if any observation exceeds the maximum token limit (4096 tokens), because such observations will be clipped during fine-tuning, resulting in data loss."
      ],
      "metadata": {
        "id": "R4FPjubmFImi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDmwM6puTLzu",
        "outputId": "f939c550-e44b-492e-a628-229e440b1b37"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 34, 166\n",
            "mean / median: 97.36, 94.0\n",
            "p5 / p95: 45.2, 145.79999999999998\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 1, 1\n",
            "mean / median: 1.0, 1.0\n",
            "p5 / p95: 1.0, 1.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOT: Test verileri için Veri yükleme, Format doğrulama, Jeton Sayım Yardımcı Programları, Veri Uyarıları ve Jeton Sayımları bölümlerinin de yapılması gerekir. Not defterini kısa tutmak için bunu sadece eğitim verileri için yaptık.\n",
        "\n",
        "\n",
        "NOTE: For test data, the Data loading, Format validation, Token Counting Utilities, Data Alerts and Token Counts sections also need to be done. To keep the notebook short, we have done this only for training data.\n",
        "Ancak maliyet tahmini bölümü yalnızca eğitim verileri için yapılır."
      ],
      "metadata": {
        "id": "Rv-y846P_hZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Estimation\n",
        "\n",
        "Bu son bölümde, ince ayar için kullanılacak toplam token sayısını tahmin ediyoruz, bu da maliyeti yaklaşık olarak tahmin etmemizi sağlıyor. Token sayısı arttıkça ince ayar işlemlerinin süresinin de artacağını belirtmekte fayda var."
      ],
      "metadata": {
        "id": "TrNGRzLzUMuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this last section, we estimate the total number of tokens that will be used for fine-tuning, which allows us to approximate the cost. It is worth noting that as the number of tokens increases, the duration of the fine-tuning process will also increase."
      ],
      "metadata": {
        "id": "C-IVRB-mFW9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "100//30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm2stEhQ-4_X",
        "outputId": "e372763c-7e09-459d-ce26-f772a7158208"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:  # train datasındaki gözlem sayısı ile TARGET_EPOCHS(3) çarpımı MIN_TARGET_EXAMPLES(100)'den küçükse,\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples) # epoch olarak MAX_DEFAULT_EPOCHS(25) veya 100//(train datasındaki gözlem sayısı)'den hangisi küçükse\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES: # train datasındaki gözlem sayısı ile TARGET_EPOCHS(3) çarpımı MAX_TARGET_EXAMPLES(25000)'den büyükse,\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples) # epoch olarak MIN_DEFAULT_EPOCHS(1) veya MIN_TARGET_EXAMPLES(25000)//(train datasındaki gözlem sayısı)'den hangisi büyükse\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens) # bir yorumun token sayısı max 4096'yı geçmeyecek şekilde tüm yorumların toplam token sayısı\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\") # eğitime tabii tutulan toplam token sayısı\n",
        "\n",
        "current_price=8 # bir milyon token başına fiyat, lütfen güncel fiyat için openai web sayfasını kontrol edin.\n",
        "print(f\"Estimate total costs ~{(n_epochs * n_billing_tokens_in_dataset)/1000000 * current_price}\")\n",
        "\n",
        "# İnce ayar için modele en az 10 gözlem verilmelidir. Aksi takdirde model hata döndürecektir. Ancak ince ayar için modele minimum 100, maksimum 25000\n",
        "# gözlem verilmesi tavsiye edilir.\n",
        "\n",
        "# GPT 3.5-Turbo modeli, ince ayar için varsayılan olarak 3 epoch ile çalışır. Ancak bu kod, verilerinizdeki gözlem sayısına göre minimum 1'den maksimum 25'e\n",
        "# kadar kaç epoch eğitim yapmanız gerektiğini size önerir.\n",
        "\n",
        "# Tüm eğitim boyunca işlenecek token sayısını ve bu token sayısına göre ince ayar maliyetini döndürür.\n",
        "\n",
        "# NOT: Bu bölüm yalnızca eğitim verilerine uygulanacaktır.\n",
        "\n",
        "\n",
        "# At least 10 observations must be given to the model for fine tuning. Otherwise the model will return an error. However, for fine tuning, the model should be given a minimum of 100 and a maximum of 25000\n",
        "# observation is recommended.\n",
        "\n",
        "# GPT 3.5-Turbo model works with 3 epochs by default for fine tuning. However, this code can be adjusted from a minimum of 1 to a maximum of 25, depending on the number of observations in your data.\n",
        "# Suggests how many epochs of training you need to do.\n",
        "\n",
        "# Returns the number of tokens to process over the entire training and the cost of fine-tuning based on this number of tokens.\n",
        "\n",
        "# NOTE: This section will only apply to training data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6iFu2fCUQLB",
        "outputId": "48e8b19f-8453-42fa-f639-463ba2ab999b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~21906 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~65718 tokens\n",
            "Estimate total costs ~0.525744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('openai_key')"
      ],
      "metadata": {
        "id": "6Mo4ro3p83PC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "#api_key=os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "yS3Hvp_gJw8O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_response = client.files.create(file=open(\"/content/train.jsonl\", \"rb\"),\n",
        "                                        purpose=\"fine-tune\") # Train datasını ince ayar için hazırlıyoruz.\n",
        "\n",
        "training_file_id = training_response.id # Hazır olan train datası için oluşturulan ID’yi çekiyoruz.\n",
        "\n",
        "validation_response = client.files.create(file=open(\"/content/test.jsonl\", \"rb\"),\n",
        "                                          purpose=\"fine-tune\") # Test datasını ince ayar için hazırlıyoruz.\n",
        "\n",
        "validation_file_id = validation_response.id # Hazır olan test datası için oluşturulan ID’yi çekiyoruz.\n",
        "\n",
        "print(\"Training file id:\", training_file_id)\n",
        "print(\"Validation file id:\", validation_file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qby3xDv2JYC8",
        "outputId": "b7ff8862-11f0-436a-ac14-3529a89f62a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training file id: file-Ff3jrpMZovt0ydTK0Evh1r05\n",
            "Validation file id: file-sbowLb2wia7VFyeS8JNTG2sL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_name = \"sentiment analys 4\"\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id, # Train datsının ID'si ince ayar modeline veriliyor. Train datasının ID'si mutlaka sağlanmalıdır\n",
        "    validation_file=validation_file_id, #Validation datsının ID'si ince ayar modeline veriliyor. Bu kimliği sağlamak isteğe bağlıdır\n",
        "    model=\"gpt-3.5-turbo\", # şimdilik mevcut tek model GPT-3.5-turbo'dur. GPT-4'ün yakın gelecekte kullanıma sunulmasını bekliyoruz.\n",
        "    suffix=suffix_name, # İnce ayar yapılan modelin ismine kendi seçeceğimiz bir ek ekleyebiliyoruz ancak modelin ismini tam olarak belirleyemiyoruz.\n",
        "    hyperparameters={\"n_epochs\":3}, # Yalnızca Epoch, batchsize ve learning_rate_multiplier parametresini ayarlamamıza izin veriliyor.\n",
        "                                    # Önerilen epoch sayısı 3 olduğundan epoch'u 3 olarak ayarladık.\n",
        ")\n",
        "\n",
        "job_id = response.id # The ID of fine-tune model.\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgw1dpVcVgPZ",
        "outputId": "2dbbb3bd-3194-40a2-f116-7f74eef945b8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FineTuningJob(id='ftjob-8QePFrG4ictRCjm2F8kOP3K9', created_at=1720723853, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-2DK8uJ3r4XlwyMWXFl6PyYe2', result_files=[], seed=1718430282, status='validating_files', trained_tokens=None, training_file='file-Ff3jrpMZovt0ydTK0Evh1r05', validation_file='file-sbowLb2wia7VFyeS8JNTG2sL', estimated_finish=None, integrations=[], user_provided_suffix='sentiment analys 4')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TjcV7BzfomDU",
        "outputId": "fd96841f-c547-456a-bea0-2c912e0b6591"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-8QePFrG4ictRCjm2F8kOP3K9'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#client.fine_tuning.jobs.retrieve(job_id) # status='validating_files', status=\"running\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ0gyFbraEiB",
        "outputId": "5361e8fc-391b-47f6-c795-62d2024f6f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-0hfuuPKC1PCqlnosHBZTCKfG', created_at=1720523850, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-b88r78OSLP9wnPnDMsswFKhJ', result_files=[], seed=1878058037, status='running', trained_tokens=None, training_file='file-Csb5pwN5aD6J6770lFi0JyOL', validation_file='file-xDzh9gWL2vxqkD7Dr4VmoTDz', estimated_finish=1720525751, integrations=[], user_provided_suffix='sentiment analys 4')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # İnce ayar hakkında genel bilgiler alıyoruz."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvYDKRtKFQGj",
        "outputId": "5a8dac47-5b39-4a3c-9800-83e5625505d8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-8QePFrG4ictRCjm2F8kOP3K9', created_at=1720723853, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-2DK8uJ3r4XlwyMWXFl6PyYe2', result_files=[], seed=1718430282, status='validating_files', trained_tokens=None, training_file='file-Ff3jrpMZovt0ydTK0Evh1r05', validation_file='file-sbowLb2wia7VFyeS8JNTG2sL', estimated_finish=None, integrations=[], user_provided_suffix='sentiment analys 4')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50) # Son 10 adımdaki ince ayar işleminin olaylarını görüntüler."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BprXKrBDIvMb",
        "outputId": "2f6059c8-bc15-43f2-c703-99966c2b247f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-us3JIopt2GQ7sOhH6yLYvcDz', created_at=1720723853, level='info', message='Validating training file: file-Ff3jrpMZovt0ydTK0Evh1r05 and validation file: file-sbowLb2wia7VFyeS8JNTG2sL', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-uncLPj33av7DcUR7imvaKrdg', created_at=1720723853, level='info', message='Created fine-tuning job: ftjob-8QePFrG4ictRCjm2F8kOP3K9', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response= client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
        "\n",
        "events=response.data"
      ],
      "metadata": {
        "id": "5rynQ-cT5EOi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events.reverse()# İnce ayar işleminin ilk adımları başlangıçta olacak şekilde, reverse() fonksiyonunu kullanarak\n",
        "                # ince ayar adımlarının sırasını tersine çeviriyoruz."
      ],
      "metadata": {
        "id": "Voa550aLVpxK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGxkxCmsNVz-",
        "outputId": "d58f1a9a-a57f-46ea-f9e7-df37a2118854"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[FineTuningJobEvent(id='ftevent-uncLPj33av7DcUR7imvaKrdg', created_at=1720723853, level='info', message='Created fine-tuning job: ftjob-8QePFrG4ictRCjm2F8kOP3K9', object='fine_tuning.job.event', data={}, type='message'),\n",
              " FineTuningJobEvent(id='ftevent-us3JIopt2GQ7sOhH6yLYvcDz', created_at=1720723853, level='info', message='Validating training file: file-Ff3jrpMZovt0ydTK0Evh1r05 and validation file: file-sbowLb2wia7VFyeS8JNTG2sL', object='fine_tuning.job.event', data={}, type='message')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in events:\n",
        "    print(event.message) #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qau4-ZN6Dw-2",
        "outputId": "3a4fb624-74dc-47ad-a04f-dc3305d1641d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created fine-tuning job: ftjob-8QePFrG4ictRCjm2F8kOP3K9\n",
            "Validating training file: file-Ff3jrpMZovt0ydTK0Evh1r05 and validation file: file-sbowLb2wia7VFyeS8JNTG2sL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#client.fine_tuning.jobs.cancel(job_id)\n",
        "\n",
        "# You can cancel the fine-tuning process you have started with this code. However, the fine-tuning process will start in 1-2 minutes,\n",
        "# so you need to cancel it before that. If you don't, you won't be able to cancel it."
      ],
      "metadata": {
        "id": "8Zq0KkGlafoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.exp(-0.14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RInjeaJrXnsE",
        "outputId": "2dd64eff-8ed0-4726-ecbb-b418db186e4b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8693582353988059"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(0.8693582353988059)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay9qZa3gY6cI",
        "outputId": "acdfb665-7a88-42af-9578-cba77826f29e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.13999999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "I1r1xR_W-LIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(job_id) # İnce ayar hakkında genel bilgiler alıyoruz öncelikle. burdan fine-tune model ismini çekeceğiz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK8s99KO-NJA",
        "outputId": "f9412737-a8eb-446e-89e0-f8cf36090453"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-8QePFrG4ictRCjm2F8kOP3K9', created_at=1720723853, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-2DK8uJ3r4XlwyMWXFl6PyYe2', result_files=[], seed=1718430282, status='running', trained_tokens=None, training_file='file-Ff3jrpMZovt0ydTK0Evh1r05', validation_file='file-sbowLb2wia7VFyeS8JNTG2sL', estimated_finish=None, integrations=[], user_provided_suffix='sentiment analys 4')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name= client.fine_tuning.jobs.retrieve(job_id).fine_tuned_model # model ismini çekiyoruz.\n",
        "model_name"
      ],
      "metadata": {
        "id": "VFaIvBdSB0Sw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the job details\n",
        "job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "# Check if the job has a fine-tuned model associated with it\n",
        "if job.fine_tuned_model:\n",
        "    model_name = job.fine_tuned_model\n",
        "    print(\"Using fine-tuned model:\", model_name)\n",
        "else:\n",
        "    # Handle the case where the job doesn't have a fine-tuned model\n",
        "    # You might want to use a default model or raise an error\n",
        "    model_name = \"gpt-3.5-turbo\"  # Replace with a suitable default model\n",
        "    print(\"No fine-tuned model found, using default model:\", model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw_N7eHmJZnJ",
        "outputId": "0596f2d9-0dbe-4ba1-ccfb-4966a3d5b905"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No fine-tuned model found, using default model: gpt-3.5-turbo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system=\"Detect sentiment in a text.\" # Tahmin için kullanacağımız system içeriği, ince ayar için kullandığımız system içeriğiyle aynıdır."
      ],
      "metadata": {
        "id": "nNF9ZE1cCgTf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test verilerinden birkaç gözlem seçip tahminlerde bulunalım.\n",
        "display(X_test.loc[139])\n",
        "display(y_test.loc[139])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "1_mOvgmbD55H",
        "outputId": "3d655ca3-a32f-4866-f3a7-9299c869e8ce"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'I love this dress! it\\'s so comfy and flowy. i wore to an event and got many compliments on the color and design of the dress. i\\'m 5\\'5\" and weigh 150.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": X_test.loc[139]}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyN_Ps9pCRMw",
        "outputId": "55efb76d-91d1-4cd5-aa32-4547fa3cc9b9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment in the text is positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(X_test.loc[85])\n",
        "display(y_test.loc[85])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "AFVlULVeEuKB",
        "outputId": "c26f214c-9adf-4701-d61e-5d45d20caf0e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'When i saw this blouse online i thought it looked like a great combination of casual with the elegance of an intricate print. i was so disappointed when it came. the print is not centered in the front or the back. it looks like they were trying to save on the material and just cut it out wherever with no thought to symmetry. for this price the detail of centering the design was expected, especially because this is how it appeared in the picture. loved the blouse, but i will be returning it becau'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": X_test.loc[85]}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asuEDLDWEvrw",
        "outputId": "619c5b9d-0ebb-4e80-83e3-ae85e6c69c51"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment in the text is mostly negative. The person expresses disappointment in the product they received, stating that the print is not centered as expected and they feel like the design was not taken care of properly. They mention that they will be returning the blouse.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cbmEtJYJmso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}